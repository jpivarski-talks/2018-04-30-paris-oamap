\documentclass[aspectratio=169]{beamer}

\mode<presentation>
{
  \usetheme{default}
  \usecolortheme{default}
  \usefonttheme{default}
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[frame number]  % or "page number"
  \setbeamercolor{frametitle}{fg=white}
  \setbeamercolor{footline}{fg=black}
} 

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{tikz}
\usepackage{courier}
\usepackage{array}
\usepackage{bold-extra}
\usepackage{minted}
\usepackage[thicklines]{cancel}

\xdefinecolor{dianablue}{rgb}{0.18,0.24,0.31}
\xdefinecolor{darkblue}{rgb}{0.1,0.1,0.7}
\xdefinecolor{darkgreen}{rgb}{0,0.5,0}
\xdefinecolor{darkgrey}{rgb}{0.35,0.35,0.35}
\xdefinecolor{darkorange}{rgb}{0.8,0.5,0}
\xdefinecolor{darkred}{rgb}{0.7,0,0}
\definecolor{darkgreen}{rgb}{0,0.6,0}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\title[2018-04-30-paris-oamap]{Object-array mapping and columnar data granularity}
\author{Jim Pivarski}
\institute{Princeton University -- DIANA-HEP}
\date{April 30, 2018}

\begin{document}

\logo{\pgfputat{\pgfxy(0.11, 7.4)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\mbox{\hspace{-8 cm}\includegraphics[height=1 cm]{princeton-logo-long.png}\includegraphics[height=1 cm]{diana-hep-logo-long.png}}}}}

\begin{frame}
  \titlepage
\end{frame}

\logo{\pgfputat{\pgfxy(0.11, 7.4)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\mbox{\hspace{-8 cm}\includegraphics[height=1 cm]{princeton-logo.png}\includegraphics[height=1 cm]{diana-hep-logo.png}}}}}

% Uncomment these lines for an automatically generated outline.
%\begin{frame}{Outline}
%  \tableofcontents
%\end{frame}

% START START START START START START START START START START START START START

\begin{frame}{Context}
\vspace{0.35 cm}
\begin{columns}[t]
\column{0.4\linewidth}
\underline{High Performance Computing (HPC)}

\vspace{0.15 cm}
\begin{itemize}
\item A lot of focus on data contiguity, CPU cache efficiency, and vectorization.
\item Data structures are often converted to flat arrays or tables, making it easier to reason about such issues.
\end{itemize}

\column{0.56\linewidth}
\begin{uncoverenv}<2->
\underline{High Energy Physics (HEP)}

\vspace{0.15 cm}
\begin{itemize}
\item Data structures are generally:

\begin{center}
\includegraphics[width=0.7\linewidth]{event-structure.pdf}
\end{center}

\item Analysis code is branchy and pointer-heavy;

``Looks more like string processing!''
\end{itemize}
\end{uncoverenv}
\end{columns}
\end{frame}

\begin{frame}{Context}
\vspace{0.5 cm}
Preparing data for analysis consists of {\it copying} parts of the centrally produced dataset.

\vspace{0.25 cm}
The choice of events to ``skim'' and which attributes to ``slim'' has to be decided before interactive data exploration is possible (timescale of seconds).

\vspace{0.5 cm}
\begin{columns}[c]
\column{0.5\linewidth}
\mbox{ } \hfill \includegraphics[height=4.5 cm]{cms-data-explosion.png}

\column{0.5\linewidth}

\vspace{0.2 cm}
\includegraphics[height=4.4 cm]{atlas-data-explosion.png} \hfill \mbox{ }
\end{columns}
\end{frame}

\begin{frame}{Context}
\vspace{0.5 cm}
It's the data structures and code branchiness that are preventing HEP from taking advantage of HPC techniques.

\vspace{0.25 cm}
\begin{itemize}\setlength{\itemsep}{0.5 cm}
\item[$\rightarrow$]<2-> Several projects underway to rewrite or rethink core reconstruction algorithms: vectorized tracking, machine learning-based pattern recognition\ldots

\item[$\rightarrow$]<3-> But a substantial part is post-reconstruction data analysis.
\begin{itemize}\setlength{\itemsep}{0.1 cm}
\item<4-> not centrally produced: ``users'' of the data
\item<5-> ad-hoc (``if we knew what we were doing, it wouldn't be called research'')
\item<6-> sometimes egregiously inefficient\ldots
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{New technique}
\vspace{0.35 cm}
\textcolor{darkblue}{\large \underline{Object-array mapping (OAMap)}}

\vspace{0.15 cm}
\begin{itemize}\setlength{\itemsep}{0.15 cm}
\item Let data analysts write traditional object-oriented code, but translate it to HPC-like array operations at runtime. (Generalization of AOS$\to$SOA.)
\item<2-> Analogy with object-relational mapping (ORM), but for low-level arrays.
\item<3-> Represent nested, variable-length object data as (unequal length) arrays of each attribute and {\it never deserialize} it into runtime objects.
\item<4-> Two ways of implementing it:

\vspace{0.05 cm}
\begin{description}\setlength{\itemsep}{0.1 cm}
\item[proxies]<5-> that simulate objects on the fly by accessing array data in response to attribute references (low-latency exploration).
\item[compiled]<6-> form that eliminates all objects, even temporary proxies, replacing user code with code that accesses array elements directly.
\end{description}
\end{itemize}

\vspace{0.2 cm}
\begin{uncoverenv}<7->
\begin{minipage}{\linewidth}
\scriptsize \textcolor{darkblue}{Prior art:} T.\ Mattis, J.\ Henning, P.\ Rein, R.\ Hirschfeld, M.\ Appeltauer, ``Columnar Objects: Improving the Performance of Analytical Applications,'' in {\it 2015 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward!),} 2015, pp.\ 197--210.
\end{minipage}
\end{uncoverenv}
\end{frame}

\begin{frame}{Not new: splitting complex data into columns}
\vspace{0.35 cm}
\textcolor{darkblue}{\large Example:} {\tt List\big(List\big(Record\big(\{"x":\ "char", "y":\ "int"\}\big)\big)\big)}

\vspace{0.25 cm}
\begin{tabular}{r l}
\small logical data & {\tt\scriptsize \textcolor{blue}{[}\textcolor{violet}{[}(\textcolor{darkorange}{a},\textcolor{darkgreen}{1}), (\textcolor{darkorange}{b},\textcolor{darkgreen}{2}), (\textcolor{darkorange}{c},\textcolor{darkgreen}{3}), (\textcolor{darkorange}{d},\textcolor{darkgreen}{4})\textcolor{violet}{]}, \textcolor{violet}{[]}, \textcolor{violet}{[}(\textcolor{darkorange}{e},\textcolor{darkgreen}{5}), (\textcolor{darkorange}{f},\textcolor{darkgreen}{6})\textcolor{violet}{]}\textcolor{blue}{]}, \textcolor{blue}{[]}, \textcolor{blue}{[}\textcolor{violet}{[}(\textcolor{darkorange}{g},\textcolor{darkgreen}{7})\textcolor{violet}{]}\textcolor{blue}{]}\ \textcolor{white}{]}} \\\hline
\small outer list stops & {\tt\scriptsize \textcolor{blue}{[\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 3,\ \ 3,\ \ \ \ \ \ \ \ \ 4]}} \\
\small inner list stops & {\tt\scriptsize \textcolor{violet}{[\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 4,\ \ 4,\ \ \ \ \ \ \ \ \ \ \ \ \ \ 6,\ \ \ \ \ \ \ \ \ \ \ \ \ 7\ ]}} \\
\small ``x'' attribute & {\tt\scriptsize \textcolor{darkorange}{[\ \ a,\ \ \ \ \ b,\ \ \ \ \ c,\ \ \ \ \ d,\ \ \ \ \ \ \ \ \ \ \ e,\ \ \ \ \ f,\ \ \ \ \ \ \ \ \ \ \ \ \ g\ \ \ \ \ ]}} \\
\small ``y'' attribute & {\tt\scriptsize \textcolor{darkgreen}{[\ \ \ \ 1,\ \ \ \ \ 2,\ \ \ \ \ 3,\ \ \ \ \ 4,\ \ \ \ \ \ \ \ \ \ \ 5,\ \ \ \ \ 6,\ \ \ \ \ \ \ \ \ \ \ \ \ 7\ \ \ ]}}
\end{tabular}

\vspace{0.35 cm}
\begin{uncoverenv}<2->
\textcolor{darkblue}{\large Transformation rules:}
\begin{itemize}
\item Primitive data at leaves of schema are stored contiguously, with no structure.
\item List structure encoded in a separate ``stops'' array, computed from the cumulative number of entries at its level of depth, written at each closing bracket.
\end{itemize}
\end{uncoverenv}

\vspace{0.1 cm}
\begin{uncoverenv}<3->
\textcolor{darkblue}{\large Variations:}
\begin{itemize}
\item Store list structure as combined ``starts'' and ``stops'': {\tt\small [0, 4, 4, 6, 7]}
\item Store as list lengths instead (smaller numbers, but not randomly accessible).
\item Dremel/Parquet's definition levels and repetition levels.
\end{itemize}
\end{uncoverenv}
\end{frame}

\begin{frame}{Also not new: split data for runtime calculations}
\vspace{0.3 cm}
\includegraphics[width=\linewidth]{apache-arrow.png}
\end{frame}

\begin{frame}[fragile]{New: viewing split data as objects for general-purpose code}
\vspace{0.1 cm}
\small
\begin{minted}{python}
>>> for event in events:
...     print(event)
...     for mu in event.Muon:
...         print("    {} {} {} {}".format(mu, mu.pt, mu.eta, mu.phi))
...
<Event at index 0>
<Event at index 1>
    <Muon at index 0> 4.00707864761 -0.517944335938 0.292175292969
<Event at index 2>
    <Muon at index 1> 49.4589920044 0.439025878906 -2.16455078125
    <Muon at index 2> 3.01149749756 -1.42895507812 -0.00624084472656
<Event at index 3>
<Event at index 4>
    <Muon at index 3> 4.55658817291 0.792846679688 1.30639648438
<Event at index 5>
    <Muon at index 4> 96.6624984741 -1.40112304688 2.5771484375
    <Muon at index 5> 11.0187826157 -1.71313476562 -2.58740234375
    <Muon at index 6> 4.674451828 -0.969848632812 0.640625
\end{minted}

\vspace{-5.5 cm}
\begin{uncoverenv}<2->
\begin{center}
\fcolorbox{black}{white}{\begin{minipage}{0.8\linewidth}
\vspace{0.25 cm}
\begin{center}
\begin{minipage}{0.9\linewidth}
The {\tt\small events} are proxies that fetch list stops on demand and each {\tt\small mu} fetches data from {\tt\small pt}, {\tt\small eta}, and {\tt\small phi} arrays on demand.

\vspace{0.25 cm}
No restriction on programming model--- any loops, function calls, branching, etc. are allowed.
\end{minipage}
\end{center}
\vspace{-0.1 cm}
\end{minipage}}
\end{center}
\end{uncoverenv}
\vspace{5.5 cm}

\vspace{-10.6 cm}
\hfill \uncover<3->{\fbox{\normalsize e.g.\ for Pandas {\tt\small DataFrame.apply(fcn)}}}
\vspace{10.6 cm}
\end{frame}

\begin{frame}[fragile]{New: compiling that code to eliminate objects altogether}
\vspace{0.15 cm}
\scriptsize
\begin{minted}{python}
>>> import numpy
>>> import numba

>>> @numba.njit                 # declares the following function to be compiled
... def compute(events, out):   # proxies can be passed in/out of compiled functions
...     i = 0
...     for event in events:    # "event" and "event.Muon" lists are a compiler fiction
...         if len(event.Muon) == 2:
...             mu1, mu2 = event.Muon[0], event.Muon[1]
...             px = mu1.px + mu2.px
...             py = mu1.py + mu2.py
...             pz = mu1.pz + mu2.pz
...             energy = mu1.energy + mu2.energy
...             out[i] = sqrt(energy**2 - px**2 - py**2 - pz**2)
...             i += 1

>>> out = numpy.empty(1921077)
>>> compute(events, out)        # compilation and array-fetching happen on first call
                                # but before execution

>>> out
array([90.22780609, 74.74654388, 89.75765991, ..., 92.06494904,
       85.44384003, 75.96061707])
\end{minted}
\end{frame}

\begin{frame}{What's happening here?}
\vspace{0.4 cm}

\textcolor{darkblue}{\large Strongly typed schema:}
\begin{itemize}
\item Primitives, lists, unions (sum types), records \& tuples (product types), pointers.
\item Describes structure and also maps elements onto array names.
\end{itemize}

\vspace{0.25 cm}
\begin{uncoverenv}<2->
\textcolor{darkblue}{\large Proxy objects:}
\begin{itemize}
\item Hold references to dict of arrays and subelement generators.
\item Overload {\tt\small \_\_getattr\_\_} and {\tt\small \_\_getitem\_\_} to generate subelement proxies or values.
\end{itemize}
\end{uncoverenv}

\begin{uncoverenv}<3->
\vspace{0.25 cm}
\textcolor{darkblue}{\large Type-inferring compiler pass:}
\begin{itemize}
\item Static type-safety against the schema.
\item Identifies a minimal set of arrays to fetch.
\end{itemize}
\end{uncoverenv}

\begin{uncoverenv}<4->
\vspace{0.25 cm}
\textcolor{darkblue}{\large Lowering compiler pass:}
\begin{itemize}
\item Each object replaced by an integer index, passed on the stack.
\item Equivalent of {\tt\small \_\_getattr\_\_} and {\tt\small \_\_getitem\_\_} emitted as LLVM pointer arithmetic.
\end{itemize}
\end{uncoverenv}
\end{frame}

\begin{frame}[fragile]{Implemented in Python as Numba extensions}
\vspace{0.15 cm}
\scriptsize
\begin{minted}{python}
@nb.typing.templates.infer
class ListProxyGetItem(nb.typing.templates.AbstractTemplate):
    key = "getitem"
    def generic(self, args, kwds):
       if len(args) == 2:
          tpe, idx = args
          if isinstance(tpe, ListProxyNumbaType) and isinstance(idx, nb.types.Integer):
             return typeof_generator(tpe.generator.content)(tpe, idx)

@nb.extending.lower_builtin("getitem", ListProxyNumbaType, nb.types.Integer)
def listproxy_getitem(context, builder, sig, args):
    listtpe, indextpe = sig.args; listval, indexval = args
    listproxy = nb.cgutils.create_struct_proxy(listtpe)(context, builder, listval)
    indexval = cast_int64(builder, indexval)

    normindex_ptr = nb.cgutils.alloca_once_value(builder, indexval)
    with builder.if_then(builder.icmp_signed("<", indexval, literal_int64(0))):
        builder.store(builder.add(indexval, listproxy.length), normindex_ptr)
    normindex = builder.load(normindex_ptr)

    at = builder.add(listproxy.whence, builder.mul(listproxy.stride, normindex))
    return generate(context, builder, listtpe.generator.content, listproxy.baggage,
                    listproxy.ptrs, listproxy.lens, at)
\end{minted}
\end{frame}




\end{document}
